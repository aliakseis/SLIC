{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import importlib\n",
    "\n",
    "from six.moves import urllib\n",
    "from shutil import copy2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracting kitti_road data.\n"
     ]
    }
   ],
   "source": [
    "def download(url, dest_directory):\n",
    "    filename = url.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "\n",
    "    logging.info(\"Download URL: {}\".format(url))\n",
    "    logging.info(\"Download DIR: {}\".format(dest_directory))\n",
    "\n",
    "    def _progress(count, block_size, total_size):\n",
    "                prog = float(count * block_size) / float(total_size) * 100.0\n",
    "                sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n",
    "                                 (filename, prog))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    filepath, _ = urllib.request.urlretrieve(url, filepath,\n",
    "                                             reporthook=_progress)\n",
    "    print()\n",
    "    return filepath\n",
    "\n",
    "\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "# Download KITTI DATA\n",
    "\n",
    "kitti_data_url = 'https://s3.eu-central-1.amazonaws.com/avg-kitti/data_road.zip'\n",
    "\n",
    "data_dir = './data'\n",
    "\n",
    "data_road_zip = './data/data_road.zip'\n",
    "\n",
    "\n",
    "if not os.path.exists(data_road_zip):\n",
    "    if kitti_data_url == '':\n",
    "        logging.error(\"Data URL for Kitti Data not provided.\")\n",
    "        url = \"http://www.cvlibs.net/download.php?file=data_road.zip\"\n",
    "        logging.error(\"Please visit: {}\".format(url))\n",
    "        logging.error(\"and request Kitti Download link.\")\n",
    "        exit(1)\n",
    "    if not kitti_data_url[-19:] == 'kitti/data_road.zip':\n",
    "        logging.error(\"Wrong url.\")\n",
    "        url = \"http://www.cvlibs.net/download.php?file=data_road.zip\"\n",
    "        logging.error(\"Please visit: {}\".format(url))\n",
    "        logging.error(\"and request Kitti Download link.\")\n",
    "        exit(1)\n",
    "    else:\n",
    "        logging.info(\"Downloading Kitti Road Data.\")\n",
    "        download(kitti_data_url, data_dir)\n",
    "\n",
    "# Extract and prepare KITTI DATA\n",
    "logging.info(\"Extracting kitti_road data.\")\n",
    "zipfile.ZipFile(data_road_zip, 'r').extractall(data_dir)\n",
    "kitti_road_dir = os.path.join(data_dir, 'data_road/')\n",
    "\n",
    "\n",
    "train_txt = \"data/train3.txt\"\n",
    "val_txt = \"data/val3.txt\"\n",
    "testing_txt = \"data/testing.txt\"\n",
    "\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getData(txt):\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "\n",
    "    with open(txt, 'r') as f:\n",
    "        for line in f:\n",
    "            sys.stdout.write('\\r>> Processing %s          ' % (line.rstrip()))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            names = line.split()\n",
    "\n",
    "            # load the image and apply SLIC and extract (approximately)\n",
    "            image = cv2.imread(os.path.join(kitti_road_dir, names[0]))\n",
    "            segments = slic(img_as_float(image), n_segments = 200, sigma = 5)\n",
    "\n",
    "            image2 = cv2.imread(os.path.join(kitti_road_dir, names[1]))\n",
    "            magenta = np.array([255, 0, 255], dtype=np.uint8)\n",
    "\n",
    "            mask2 = np.all(image2 == magenta, axis = -1)\n",
    "\n",
    "            # loop over the unique segment values\n",
    "            for (i, segVal) in enumerate(np.unique(segments)):\n",
    "                # construct a mask for the segment\n",
    "                mask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "                mask[segments == segVal] = 255\n",
    "\n",
    "                m = cv2.moments(mask, True);\n",
    "\n",
    "                x = m[\"m10\"]/m[\"m00\"]\n",
    "                y = m[\"m01\"]/m[\"m00\"]\n",
    "\n",
    "                intersection = np.logical_and(mask, mask2)\n",
    "\n",
    "                img = cv2.bitwise_and(image, image, mask = mask)\n",
    "\n",
    "                #crop\n",
    "                img = img[int(y - img_rows/2) : int(y + img_rows/2), \n",
    "                          int(x - img_cols/2) : int(x + img_cols/2)]\n",
    "\n",
    "                old_size = img.shape[:2]\n",
    "                delta_w = img_cols - old_size[1]#img.cols\n",
    "                delta_h = img_rows - old_size[0]#img.rows\n",
    "                top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "                left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "                img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "\n",
    "                value = int(np.sum(intersection) > m[\"m00\"] / 2)\n",
    "\n",
    "                all_x.append([img])\n",
    "                all_y.append([value])\n",
    "\n",
    "                flipHorizontal = cv2.flip(img, 1)\n",
    "                all_x.append([flipHorizontal])\n",
    "                all_y.append([value])\n",
    "\n",
    "    all_x = np.concatenate(all_x)\n",
    "    all_y = np.concatenate(all_y)\n",
    "\n",
    "    return all_x, all_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Processing training/image_2/uu_000097.png training/gt_image_2/uu_road_000097.png            "
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train) = getData(train_txt)\n",
    "(x_test, y_test) = getData(val_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (87160, 48, 48, 3)\n",
      "y_train shape: (87160,)\n",
      "87160 train samples\n",
      "17336 test samples\n",
      "WARNING:tensorflow:From C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 87160 samples, validate on 17336 samples\n",
      "Epoch 1/12\n",
      "87160/87160 [==============================] - 40s 464us/step - loss: 0.2411 - accuracy: 0.8896 - val_loss: 0.2206 - val_accuracy: 0.9087\n",
      "Epoch 2/12\n",
      "87160/87160 [==============================] - 34s 386us/step - loss: 0.1655 - accuracy: 0.9293 - val_loss: 0.2492 - val_accuracy: 0.9049\n",
      "Epoch 3/12\n",
      "87160/87160 [==============================] - 34s 386us/step - loss: 0.1518 - accuracy: 0.9358 - val_loss: 0.1959 - val_accuracy: 0.9237\n",
      "Epoch 4/12\n",
      "87160/87160 [==============================] - 34s 386us/step - loss: 0.1431 - accuracy: 0.9397 - val_loss: 0.1827 - val_accuracy: 0.9320\n",
      "Epoch 5/12\n",
      "87160/87160 [==============================] - 34s 387us/step - loss: 0.1326 - accuracy: 0.9443 - val_loss: 0.1855 - val_accuracy: 0.9352\n",
      "Epoch 6/12\n",
      "87160/87160 [==============================] - 34s 387us/step - loss: 0.1240 - accuracy: 0.9481 - val_loss: 0.1910 - val_accuracy: 0.9322\n",
      "Epoch 7/12\n",
      "87160/87160 [==============================] - 34s 386us/step - loss: 0.1151 - accuracy: 0.9521 - val_loss: 0.1653 - val_accuracy: 0.9399\n",
      "Epoch 8/12\n",
      "87160/87160 [==============================] - 34s 386us/step - loss: 0.1052 - accuracy: 0.9560 - val_loss: 0.1630 - val_accuracy: 0.9416\n",
      "Epoch 9/12\n",
      "87160/87160 [==============================] - 34s 386us/step - loss: 0.0972 - accuracy: 0.9608 - val_loss: 0.2065 - val_accuracy: 0.9400\n",
      "Epoch 10/12\n",
      "87160/87160 [==============================] - 34s 386us/step - loss: 0.0904 - accuracy: 0.9637 - val_loss: 0.1843 - val_accuracy: 0.9425\n",
      "Epoch 11/12\n",
      "87160/87160 [==============================] - 34s 386us/step - loss: 0.0823 - accuracy: 0.9676 - val_loss: 0.2246 - val_accuracy: 0.9427\n",
      "Epoch 12/12\n",
      "87160/87160 [==============================] - 34s 386us/step - loss: 0.0775 - accuracy: 0.9697 - val_loss: 0.1987 - val_accuracy: 0.9478\n",
      "Test loss: 0.19865656228689116\n",
      "Test accuracy: 0.9477964639663696\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
    "    input_shape = (3, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "    input_shape = (img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
