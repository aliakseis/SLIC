{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import importlib\n",
    "\n",
    "from six.moves import urllib\n",
    "from shutil import copy2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracting kitti_road data.\n"
     ]
    }
   ],
   "source": [
    "def download(url, dest_directory):\n",
    "    filename = url.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "\n",
    "    logging.info(\"Download URL: {}\".format(url))\n",
    "    logging.info(\"Download DIR: {}\".format(dest_directory))\n",
    "\n",
    "    def _progress(count, block_size, total_size):\n",
    "                prog = float(count * block_size) / float(total_size) * 100.0\n",
    "                sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n",
    "                                 (filename, prog))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    filepath, _ = urllib.request.urlretrieve(url, filepath,\n",
    "                                             reporthook=_progress)\n",
    "    print()\n",
    "    return filepath\n",
    "\n",
    "\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "# Download KITTI DATA\n",
    "\n",
    "kitti_data_url = 'https://s3.eu-central-1.amazonaws.com/avg-kitti/data_road.zip'\n",
    "\n",
    "data_dir = './data'\n",
    "\n",
    "data_road_zip = './data/data_road.zip'\n",
    "\n",
    "\n",
    "if not os.path.exists(data_road_zip):\n",
    "    if kitti_data_url == '':\n",
    "        logging.error(\"Data URL for Kitti Data not provided.\")\n",
    "        url = \"http://www.cvlibs.net/download.php?file=data_road.zip\"\n",
    "        logging.error(\"Please visit: {}\".format(url))\n",
    "        logging.error(\"and request Kitti Download link.\")\n",
    "        logging.error(\"Rerun scipt using\"\n",
    "                      \"'python download_data.py' --kitti_url [url]\")\n",
    "        exit(1)\n",
    "    if not kitti_data_url[-19:] == 'kitti/data_road.zip':\n",
    "        logging.error(\"Wrong url.\")\n",
    "        url = \"http://www.cvlibs.net/download.php?file=data_road.zip\"\n",
    "        logging.error(\"Please visit: {}\".format(url))\n",
    "        logging.error(\"and request Kitti Download link.\")\n",
    "        logging.error(\"Rerun scipt using\"\n",
    "                      \"'python download_data.py' --kitti_url [url]\")\n",
    "        exit(1)\n",
    "    else:\n",
    "        logging.info(\"Downloading Kitti Road Data.\")\n",
    "        download(kitti_data_url, data_dir)\n",
    "\n",
    "# Extract and prepare KITTI DATA\n",
    "logging.info(\"Extracting kitti_road data.\")\n",
    "zipfile.ZipFile(data_road_zip, 'r').extractall(data_dir)\n",
    "kitti_road_dir = os.path.join(data_dir, 'data_road/')\n",
    "\n",
    "#logging.info(\"Preparing kitti_road data.\")\n",
    "\n",
    "train_txt = \"data/train3.txt\"\n",
    "val_txt = \"data/val3.txt\"\n",
    "testing_txt = \"data/testing.txt\"\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "#copy2(train_txt, kitti_road_dir)\n",
    "#copy2(val_txt, kitti_road_dir)\n",
    "#copy2(testing_txt, kitti_road_dir)\n",
    "\n",
    "#logging.info(\"All data have been downloaded successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getData(txt):\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "\n",
    "    with open(txt, 'r') as f:\n",
    "        for line in f:\n",
    "            names = line.split()\n",
    "            logging.info(names[0])\n",
    "            #logging.info(names[1])        \n",
    "            # load the image and apply SLIC and extract (approximately)\n",
    "\n",
    "            # the supplied number of segments\n",
    "            image = cv2.imread(os.path.join(kitti_road_dir, names[0]))\n",
    "            segments = slic(img_as_float(image), n_segments = 200, sigma = 5)\n",
    "\n",
    "            image2 = cv2.imread(os.path.join(kitti_road_dir, names[1]))\n",
    "            magenta = np.array([255, 0, 255], dtype=np.uint8)\n",
    "            #mask2 = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "            #mask2[image2 == magenta] = 255\n",
    "\n",
    "            #data = np.array(image2)\n",
    "            #rgb = data[:,:,:3]\n",
    "            #mask2 = np.all(rgb == magenta, axis = -1)\n",
    "\n",
    "            #lower_magenta = np.array([254,0,254])\n",
    "            #upper_magenta = np.array([255,1,255])\n",
    "            #mask2 = cv2.inRange(image2 , lower_magenta, upper_magenta)        \n",
    "\n",
    "            # ok\n",
    "            mask2 = np.all(image2 == magenta, axis = -1)\n",
    "            #plt.imshow(mask2)\n",
    "\n",
    "            # show the output of SLIC\n",
    "            #fig = plt.figure(\"Superpixels\")\n",
    "            #ax = fig.add_subplot(1, 1, 1)\n",
    "            #ax.imshow(mark_boundaries(img_as_float(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)), segments))\n",
    "            #plt.axis(\"off\")\n",
    "            #plt.show()\n",
    "            # loop over the unique segment values\n",
    "            for (i, segVal) in enumerate(np.unique(segments)):\n",
    "                # construct a mask for the segment\n",
    "                #print(\"[x] inspecting segment %d\" % (i))\n",
    "\n",
    "                mask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "                mask[segments == segVal] = 255\n",
    "\n",
    "                m = cv2.moments(mask, True);\n",
    "                #print(\"centroid coordinates %d : %d\" % (m[\"m10\"]/m[\"m00\"], m[\"m01\"]/m[\"m00\"]))\n",
    "\n",
    "                x = m[\"m10\"]/m[\"m00\"]\n",
    "                y = m[\"m01\"]/m[\"m00\"]\n",
    "\n",
    "                intersection = np.logical_and(mask, mask2)\n",
    "\n",
    "\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                img = cv2.bitwise_and(gray, gray, mask = mask)\n",
    "\n",
    "                #intersection_mask = intersection.astype(np.uint8)\n",
    "                #intersection_mask *= 255\n",
    "                #img2 = cv2.bitwise_and(gray, gray, mask = intersection_mask)\n",
    "                #img2 = img2[int(y - img_rows/2) : int(y + img_rows/2), int(x - img_cols/2) : int(x + img_cols/2)]\n",
    "\n",
    "                #crop\n",
    "                img = img[int(y - img_rows/2) : int(y + img_rows/2), int(x - img_cols/2) : int(x + img_cols/2)]\n",
    "\n",
    "                old_size = img.shape[:2]\n",
    "                delta_w = img_cols - old_size[1]#img.cols\n",
    "                delta_h = img_rows - old_size[0]#img.rows\n",
    "                top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "                left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "                img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "\n",
    "                value = int(np.sum(intersection) > m[\"m00\"] / 2)\n",
    "                #print(\"value %d\" % (value))\n",
    "\n",
    "                #all_x.append(np.asarray(img[:,:]))\n",
    "                all_x.append([img])\n",
    "                all_y.append([value])\n",
    "\n",
    "\n",
    "                #print(\"value %d\" % (value))\n",
    "\n",
    "                #if intersection.any():\n",
    "                #if m[\"m00\"] == np.sum(intersection):\n",
    "                #if np.sum(intersection) > m[\"m00\"] / 2:\n",
    "\n",
    "                # show the masked region\n",
    "                #v2.imshow(\"Mask\", mask)\n",
    "                #v2.imshow(\"Applied\", cv2.bitwise_and(image, image, mask = mask))\n",
    "\n",
    "                    #print(\"centroid, intersection counts %d %d\" % (m[\"m00\"], np.sum(intersection)))\n",
    "\n",
    "                    #m = cv2.moments(mask, True);\n",
    "                    #print(\"centroid coordinates %d : %d\" % (m[\"m10\"]/m[\"m00\"], m[\"m01\"]/m[\"m00\"]))\n",
    "\n",
    "                    #img = cv2.bitwise_and(image, image, mask = mask)\n",
    "                    #plt.imshow(img)\n",
    "                    #plt.imshow(img)\n",
    "                    #break\n",
    "            #break\n",
    "\n",
    "    all_x = np.concatenate(all_x)\n",
    "    all_y = np.concatenate(all_y)\n",
    "\n",
    "    #all_x = all_x.astype('float32')\n",
    "    #print('all_x shape:', all_x.shape)\n",
    "    #print(all_x)\n",
    "    #print('all_y shape:', all_y.shape)\n",
    "\n",
    "    return all_x, all_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:training/image_2/um_000000.png\n",
      "INFO:root:training/image_2/um_000001.png\n",
      "INFO:root:training/image_2/um_000002.png\n",
      "INFO:root:training/image_2/um_000003.png\n",
      "INFO:root:training/image_2/um_000004.png\n",
      "INFO:root:training/image_2/um_000005.png\n",
      "INFO:root:training/image_2/um_000006.png\n",
      "INFO:root:training/image_2/um_000007.png\n",
      "INFO:root:training/image_2/um_000008.png\n",
      "INFO:root:training/image_2/um_000009.png\n",
      "INFO:root:training/image_2/um_000010.png\n",
      "INFO:root:training/image_2/um_000011.png\n",
      "INFO:root:training/image_2/um_000012.png\n",
      "INFO:root:training/image_2/um_000013.png\n",
      "INFO:root:training/image_2/um_000014.png\n",
      "INFO:root:training/image_2/um_000015.png\n",
      "INFO:root:training/image_2/um_000016.png\n",
      "INFO:root:training/image_2/um_000017.png\n",
      "INFO:root:training/image_2/um_000018.png\n",
      "INFO:root:training/image_2/um_000019.png\n",
      "INFO:root:training/image_2/um_000020.png\n",
      "INFO:root:training/image_2/um_000021.png\n",
      "INFO:root:training/image_2/um_000022.png\n",
      "INFO:root:training/image_2/um_000023.png\n",
      "INFO:root:training/image_2/um_000024.png\n",
      "INFO:root:training/image_2/um_000025.png\n",
      "INFO:root:training/image_2/um_000026.png\n",
      "INFO:root:training/image_2/um_000027.png\n",
      "INFO:root:training/image_2/um_000028.png\n",
      "INFO:root:training/image_2/um_000029.png\n",
      "INFO:root:training/image_2/um_000030.png\n",
      "INFO:root:training/image_2/um_000031.png\n",
      "INFO:root:training/image_2/um_000032.png\n",
      "INFO:root:training/image_2/um_000033.png\n",
      "INFO:root:training/image_2/um_000034.png\n",
      "INFO:root:training/image_2/um_000035.png\n",
      "INFO:root:training/image_2/um_000036.png\n",
      "INFO:root:training/image_2/um_000037.png\n",
      "INFO:root:training/image_2/um_000038.png\n",
      "INFO:root:training/image_2/um_000039.png\n",
      "INFO:root:training/image_2/um_000040.png\n",
      "INFO:root:training/image_2/um_000041.png\n",
      "INFO:root:training/image_2/um_000042.png\n",
      "INFO:root:training/image_2/um_000043.png\n",
      "INFO:root:training/image_2/um_000044.png\n",
      "INFO:root:training/image_2/um_000045.png\n",
      "INFO:root:training/image_2/um_000046.png\n",
      "INFO:root:training/image_2/um_000047.png\n",
      "INFO:root:training/image_2/um_000048.png\n",
      "INFO:root:training/image_2/um_000049.png\n",
      "INFO:root:training/image_2/um_000050.png\n",
      "INFO:root:training/image_2/um_000051.png\n",
      "INFO:root:training/image_2/um_000052.png\n",
      "INFO:root:training/image_2/um_000053.png\n",
      "INFO:root:training/image_2/um_000054.png\n",
      "INFO:root:training/image_2/um_000055.png\n",
      "INFO:root:training/image_2/um_000056.png\n",
      "INFO:root:training/image_2/um_000057.png\n",
      "INFO:root:training/image_2/um_000058.png\n",
      "INFO:root:training/image_2/um_000059.png\n",
      "INFO:root:training/image_2/um_000060.png\n",
      "INFO:root:training/image_2/um_000061.png\n",
      "INFO:root:training/image_2/um_000062.png\n",
      "INFO:root:training/image_2/um_000063.png\n",
      "INFO:root:training/image_2/um_000064.png\n",
      "INFO:root:training/image_2/um_000065.png\n",
      "INFO:root:training/image_2/um_000066.png\n",
      "INFO:root:training/image_2/um_000067.png\n",
      "INFO:root:training/image_2/um_000068.png\n",
      "INFO:root:training/image_2/um_000069.png\n",
      "INFO:root:training/image_2/um_000070.png\n",
      "INFO:root:training/image_2/um_000071.png\n",
      "INFO:root:training/image_2/um_000072.png\n",
      "INFO:root:training/image_2/um_000073.png\n",
      "INFO:root:training/image_2/um_000074.png\n",
      "INFO:root:training/image_2/um_000075.png\n",
      "INFO:root:training/image_2/um_000076.png\n",
      "INFO:root:training/image_2/um_000077.png\n",
      "INFO:root:training/image_2/um_000078.png\n",
      "INFO:root:training/image_2/umm_000000.png\n",
      "INFO:root:training/image_2/umm_000001.png\n",
      "INFO:root:training/image_2/umm_000002.png\n",
      "INFO:root:training/image_2/umm_000003.png\n",
      "INFO:root:training/image_2/umm_000004.png\n",
      "INFO:root:training/image_2/umm_000005.png\n",
      "INFO:root:training/image_2/umm_000006.png\n",
      "INFO:root:training/image_2/umm_000007.png\n",
      "INFO:root:training/image_2/umm_000008.png\n",
      "INFO:root:training/image_2/umm_000009.png\n",
      "INFO:root:training/image_2/umm_000010.png\n",
      "INFO:root:training/image_2/umm_000011.png\n",
      "INFO:root:training/image_2/umm_000012.png\n",
      "INFO:root:training/image_2/umm_000013.png\n",
      "INFO:root:training/image_2/umm_000014.png\n",
      "INFO:root:training/image_2/umm_000015.png\n",
      "INFO:root:training/image_2/umm_000016.png\n",
      "INFO:root:training/image_2/umm_000017.png\n",
      "INFO:root:training/image_2/umm_000018.png\n",
      "INFO:root:training/image_2/umm_000019.png\n",
      "INFO:root:training/image_2/umm_000020.png\n",
      "INFO:root:training/image_2/umm_000021.png\n",
      "INFO:root:training/image_2/umm_000022.png\n",
      "INFO:root:training/image_2/umm_000023.png\n",
      "INFO:root:training/image_2/umm_000024.png\n",
      "INFO:root:training/image_2/umm_000025.png\n",
      "INFO:root:training/image_2/umm_000026.png\n",
      "INFO:root:training/image_2/umm_000027.png\n",
      "INFO:root:training/image_2/umm_000028.png\n",
      "INFO:root:training/image_2/umm_000029.png\n",
      "INFO:root:training/image_2/umm_000030.png\n",
      "INFO:root:training/image_2/umm_000031.png\n",
      "INFO:root:training/image_2/umm_000032.png\n",
      "INFO:root:training/image_2/umm_000033.png\n",
      "INFO:root:training/image_2/umm_000034.png\n",
      "INFO:root:training/image_2/umm_000035.png\n",
      "INFO:root:training/image_2/umm_000036.png\n",
      "INFO:root:training/image_2/umm_000037.png\n",
      "INFO:root:training/image_2/umm_000038.png\n",
      "INFO:root:training/image_2/umm_000039.png\n",
      "INFO:root:training/image_2/umm_000040.png\n",
      "INFO:root:training/image_2/umm_000041.png\n",
      "INFO:root:training/image_2/umm_000042.png\n",
      "INFO:root:training/image_2/umm_000043.png\n",
      "INFO:root:training/image_2/umm_000044.png\n",
      "INFO:root:training/image_2/umm_000045.png\n",
      "INFO:root:training/image_2/umm_000046.png\n",
      "INFO:root:training/image_2/umm_000047.png\n",
      "INFO:root:training/image_2/umm_000048.png\n",
      "INFO:root:training/image_2/umm_000049.png\n",
      "INFO:root:training/image_2/umm_000050.png\n",
      "INFO:root:training/image_2/umm_000051.png\n",
      "INFO:root:training/image_2/umm_000052.png\n",
      "INFO:root:training/image_2/umm_000053.png\n",
      "INFO:root:training/image_2/umm_000054.png\n",
      "INFO:root:training/image_2/umm_000055.png\n",
      "INFO:root:training/image_2/umm_000056.png\n",
      "INFO:root:training/image_2/umm_000057.png\n",
      "INFO:root:training/image_2/umm_000058.png\n",
      "INFO:root:training/image_2/umm_000059.png\n",
      "INFO:root:training/image_2/umm_000060.png\n",
      "INFO:root:training/image_2/umm_000061.png\n",
      "INFO:root:training/image_2/umm_000062.png\n",
      "INFO:root:training/image_2/umm_000063.png\n",
      "INFO:root:training/image_2/umm_000064.png\n",
      "INFO:root:training/image_2/umm_000065.png\n",
      "INFO:root:training/image_2/umm_000066.png\n",
      "INFO:root:training/image_2/umm_000067.png\n",
      "INFO:root:training/image_2/umm_000068.png\n",
      "INFO:root:training/image_2/umm_000069.png\n",
      "INFO:root:training/image_2/umm_000070.png\n",
      "INFO:root:training/image_2/umm_000071.png\n",
      "INFO:root:training/image_2/umm_000072.png\n",
      "INFO:root:training/image_2/umm_000073.png\n",
      "INFO:root:training/image_2/umm_000074.png\n",
      "INFO:root:training/image_2/umm_000075.png\n",
      "INFO:root:training/image_2/umm_000076.png\n",
      "INFO:root:training/image_2/umm_000077.png\n",
      "INFO:root:training/image_2/umm_000078.png\n",
      "INFO:root:training/image_2/umm_000079.png\n",
      "INFO:root:training/image_2/uu_000000.png\n",
      "INFO:root:training/image_2/uu_000001.png\n",
      "INFO:root:training/image_2/uu_000002.png\n",
      "INFO:root:training/image_2/uu_000003.png\n",
      "INFO:root:training/image_2/uu_000004.png\n",
      "INFO:root:training/image_2/uu_000005.png\n",
      "INFO:root:training/image_2/uu_000006.png\n",
      "INFO:root:training/image_2/uu_000007.png\n",
      "INFO:root:training/image_2/uu_000008.png\n",
      "INFO:root:training/image_2/uu_000009.png\n",
      "INFO:root:training/image_2/uu_000010.png\n",
      "INFO:root:training/image_2/uu_000011.png\n",
      "INFO:root:training/image_2/uu_000012.png\n",
      "INFO:root:training/image_2/uu_000013.png\n",
      "INFO:root:training/image_2/uu_000014.png\n",
      "INFO:root:training/image_2/uu_000015.png\n",
      "INFO:root:training/image_2/uu_000016.png\n",
      "INFO:root:training/image_2/uu_000017.png\n",
      "INFO:root:training/image_2/uu_000018.png\n",
      "INFO:root:training/image_2/uu_000019.png\n",
      "INFO:root:training/image_2/uu_000020.png\n",
      "INFO:root:training/image_2/uu_000021.png\n",
      "INFO:root:training/image_2/uu_000022.png\n",
      "INFO:root:training/image_2/uu_000023.png\n",
      "INFO:root:training/image_2/uu_000024.png\n",
      "INFO:root:training/image_2/uu_000025.png\n",
      "INFO:root:training/image_2/uu_000026.png\n",
      "INFO:root:training/image_2/uu_000027.png\n",
      "INFO:root:training/image_2/uu_000028.png\n",
      "INFO:root:training/image_2/uu_000029.png\n",
      "INFO:root:training/image_2/uu_000030.png\n",
      "INFO:root:training/image_2/uu_000031.png\n",
      "INFO:root:training/image_2/uu_000032.png\n",
      "INFO:root:training/image_2/uu_000033.png\n",
      "INFO:root:training/image_2/uu_000034.png\n",
      "INFO:root:training/image_2/uu_000035.png\n",
      "INFO:root:training/image_2/uu_000036.png\n",
      "INFO:root:training/image_2/uu_000037.png\n",
      "INFO:root:training/image_2/uu_000038.png\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:training/image_2/uu_000039.png\n",
      "INFO:root:training/image_2/uu_000040.png\n",
      "INFO:root:training/image_2/uu_000041.png\n",
      "INFO:root:training/image_2/uu_000042.png\n",
      "INFO:root:training/image_2/uu_000043.png\n",
      "INFO:root:training/image_2/uu_000044.png\n",
      "INFO:root:training/image_2/uu_000045.png\n",
      "INFO:root:training/image_2/uu_000046.png\n",
      "INFO:root:training/image_2/uu_000047.png\n",
      "INFO:root:training/image_2/uu_000048.png\n",
      "INFO:root:training/image_2/uu_000049.png\n",
      "INFO:root:training/image_2/uu_000050.png\n",
      "INFO:root:training/image_2/uu_000051.png\n",
      "INFO:root:training/image_2/uu_000052.png\n",
      "INFO:root:training/image_2/uu_000053.png\n",
      "INFO:root:training/image_2/uu_000054.png\n",
      "INFO:root:training/image_2/uu_000055.png\n",
      "INFO:root:training/image_2/uu_000056.png\n",
      "INFO:root:training/image_2/uu_000057.png\n",
      "INFO:root:training/image_2/uu_000058.png\n",
      "INFO:root:training/image_2/uu_000059.png\n",
      "INFO:root:training/image_2/uu_000060.png\n",
      "INFO:root:training/image_2/uu_000061.png\n",
      "INFO:root:training/image_2/uu_000062.png\n",
      "INFO:root:training/image_2/uu_000063.png\n",
      "INFO:root:training/image_2/uu_000064.png\n",
      "INFO:root:training/image_2/uu_000065.png\n",
      "INFO:root:training/image_2/uu_000066.png\n",
      "INFO:root:training/image_2/uu_000067.png\n",
      "INFO:root:training/image_2/uu_000068.png\n",
      "INFO:root:training/image_2/uu_000069.png\n",
      "INFO:root:training/image_2/uu_000070.png\n",
      "INFO:root:training/image_2/uu_000071.png\n",
      "INFO:root:training/image_2/uu_000072.png\n",
      "INFO:root:training/image_2/uu_000073.png\n",
      "INFO:root:training/image_2/uu_000074.png\n",
      "INFO:root:training/image_2/uu_000075.png\n",
      "INFO:root:training/image_2/uu_000076.png\n",
      "INFO:root:training/image_2/uu_000077.png\n",
      "INFO:root:training/image_2/uu_000078.png\n",
      "INFO:root:training/image_2/uu_000079.png\n",
      "INFO:root:training/image_2/uu_000080.png\n",
      "INFO:root:training/image_2/uu_000081.png\n",
      "INFO:root:training/image_2/um_000079.png\n",
      "INFO:root:training/image_2/um_000080.png\n",
      "INFO:root:training/image_2/um_000081.png\n",
      "INFO:root:training/image_2/um_000082.png\n",
      "INFO:root:training/image_2/um_000083.png\n",
      "INFO:root:training/image_2/um_000084.png\n",
      "INFO:root:training/image_2/um_000085.png\n",
      "INFO:root:training/image_2/um_000086.png\n",
      "INFO:root:training/image_2/um_000087.png\n",
      "INFO:root:training/image_2/um_000088.png\n",
      "INFO:root:training/image_2/um_000089.png\n",
      "INFO:root:training/image_2/um_000090.png\n",
      "INFO:root:training/image_2/um_000091.png\n",
      "INFO:root:training/image_2/um_000092.png\n",
      "INFO:root:training/image_2/um_000093.png\n",
      "INFO:root:training/image_2/um_000094.png\n",
      "INFO:root:training/image_2/umm_000080.png\n",
      "INFO:root:training/image_2/umm_000081.png\n",
      "INFO:root:training/image_2/umm_000082.png\n",
      "INFO:root:training/image_2/umm_000083.png\n",
      "INFO:root:training/image_2/umm_000084.png\n",
      "INFO:root:training/image_2/umm_000085.png\n",
      "INFO:root:training/image_2/umm_000086.png\n",
      "INFO:root:training/image_2/umm_000087.png\n",
      "INFO:root:training/image_2/umm_000088.png\n",
      "INFO:root:training/image_2/umm_000089.png\n",
      "INFO:root:training/image_2/umm_000090.png\n",
      "INFO:root:training/image_2/umm_000091.png\n",
      "INFO:root:training/image_2/umm_000092.png\n",
      "INFO:root:training/image_2/umm_000093.png\n",
      "INFO:root:training/image_2/umm_000094.png\n",
      "INFO:root:training/image_2/umm_000095.png\n",
      "INFO:root:training/image_2/uu_000082.png\n",
      "INFO:root:training/image_2/uu_000083.png\n",
      "INFO:root:training/image_2/uu_000084.png\n",
      "INFO:root:training/image_2/uu_000085.png\n",
      "INFO:root:training/image_2/uu_000086.png\n",
      "INFO:root:training/image_2/uu_000087.png\n",
      "INFO:root:training/image_2/uu_000088.png\n",
      "INFO:root:training/image_2/uu_000089.png\n",
      "INFO:root:training/image_2/uu_000090.png\n",
      "INFO:root:training/image_2/uu_000091.png\n",
      "INFO:root:training/image_2/uu_000092.png\n",
      "INFO:root:training/image_2/uu_000093.png\n",
      "INFO:root:training/image_2/uu_000094.png\n",
      "INFO:root:training/image_2/uu_000095.png\n",
      "INFO:root:training/image_2/uu_000096.png\n",
      "INFO:root:training/image_2/uu_000097.png\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train) = getData(train_txt)\n",
    "(x_test, y_test) = getData(val_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (43580, 48, 48, 1)\n",
      "y_train shape: (43580,)\n",
      "43580 train samples\n",
      "8668 test samples\n",
      "WARNING:tensorflow:From C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 43580 samples, validate on 8668 samples\n",
      "Epoch 1/12\n",
      "43580/43580 [==============================] - 24s 554us/step - loss: 0.3674 - accuracy: 0.8377 - val_loss: 0.3278 - val_accuracy: 0.8546\n",
      "Epoch 2/12\n",
      "43580/43580 [==============================] - 20s 448us/step - loss: 0.2834 - accuracy: 0.8807 - val_loss: 0.2563 - val_accuracy: 0.8909\n",
      "Epoch 3/12\n",
      "43580/43580 [==============================] - 20s 448us/step - loss: 0.2493 - accuracy: 0.8898 - val_loss: 0.2431 - val_accuracy: 0.8936\n",
      "Epoch 4/12\n",
      "43580/43580 [==============================] - 20s 448us/step - loss: 0.2316 - accuracy: 0.8968 - val_loss: 0.2527 - val_accuracy: 0.8854\n",
      "Epoch 5/12\n",
      "43580/43580 [==============================] - 20s 448us/step - loss: 0.2164 - accuracy: 0.9051 - val_loss: 0.2702 - val_accuracy: 0.8910\n",
      "Epoch 6/12\n",
      "43580/43580 [==============================] - 20s 449us/step - loss: 0.2076 - accuracy: 0.9089 - val_loss: 0.2296 - val_accuracy: 0.8905\n",
      "Epoch 7/12\n",
      "43580/43580 [==============================] - 20s 450us/step - loss: 0.1923 - accuracy: 0.9151 - val_loss: 0.2560 - val_accuracy: 0.8808\n",
      "Epoch 8/12\n",
      "43580/43580 [==============================] - 20s 450us/step - loss: 0.1784 - accuracy: 0.9242 - val_loss: 0.2450 - val_accuracy: 0.8932\n",
      "Epoch 9/12\n",
      "43580/43580 [==============================] - 20s 450us/step - loss: 0.1603 - accuracy: 0.9324 - val_loss: 0.2140 - val_accuracy: 0.9108\n",
      "Epoch 10/12\n",
      "43580/43580 [==============================] - 20s 450us/step - loss: 0.1471 - accuracy: 0.9391 - val_loss: 0.2151 - val_accuracy: 0.9029\n",
      "Epoch 11/12\n",
      "43580/43580 [==============================] - 20s 451us/step - loss: 0.1325 - accuracy: 0.9460 - val_loss: 0.1947 - val_accuracy: 0.9086\n",
      "Epoch 12/12\n",
      "43580/43580 [==============================] - 20s 451us/step - loss: 0.1210 - accuracy: 0.9512 - val_loss: 0.1952 - val_accuracy: 0.9229\n",
      "Test loss: 0.19521323372924052\n",
      "Test accuracy: 0.9229349493980408\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(52, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
