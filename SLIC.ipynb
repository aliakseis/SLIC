{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import zipfile\n",
    "\n",
    "import importlib\n",
    "\n",
    "from six.moves import urllib\n",
    "from shutil import copy2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 2\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Extracting kitti_road data.\n"
     ]
    }
   ],
   "source": [
    "def download(url, dest_directory):\n",
    "    filename = url.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "\n",
    "    logging.info(\"Download URL: {}\".format(url))\n",
    "    logging.info(\"Download DIR: {}\".format(dest_directory))\n",
    "\n",
    "    def _progress(count, block_size, total_size):\n",
    "                prog = float(count * block_size) / float(total_size) * 100.0\n",
    "                sys.stdout.write('\\r>> Downloading %s %.1f%%' %\n",
    "                                 (filename, prog))\n",
    "                sys.stdout.flush()\n",
    "\n",
    "    filepath, _ = urllib.request.urlretrieve(url, filepath,\n",
    "                                             reporthook=_progress)\n",
    "    print()\n",
    "    return filepath\n",
    "\n",
    "\n",
    "importlib.reload(logging)\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "\n",
    "# Download KITTI DATA\n",
    "\n",
    "kitti_data_url = 'https://s3.eu-central-1.amazonaws.com/avg-kitti/data_road.zip'\n",
    "\n",
    "data_dir = './data'\n",
    "\n",
    "data_road_zip = './data/data_road.zip'\n",
    "\n",
    "\n",
    "if not os.path.exists(data_road_zip):\n",
    "    if kitti_data_url == '':\n",
    "        logging.error(\"Data URL for Kitti Data not provided.\")\n",
    "        url = \"http://www.cvlibs.net/download.php?file=data_road.zip\"\n",
    "        logging.error(\"Please visit: {}\".format(url))\n",
    "        logging.error(\"and request Kitti Download link.\")\n",
    "        logging.error(\"Rerun scipt using\"\n",
    "                      \"'python download_data.py' --kitti_url [url]\")\n",
    "        exit(1)\n",
    "    if not kitti_data_url[-19:] == 'kitti/data_road.zip':\n",
    "        logging.error(\"Wrong url.\")\n",
    "        url = \"http://www.cvlibs.net/download.php?file=data_road.zip\"\n",
    "        logging.error(\"Please visit: {}\".format(url))\n",
    "        logging.error(\"and request Kitti Download link.\")\n",
    "        logging.error(\"Rerun scipt using\"\n",
    "                      \"'python download_data.py' --kitti_url [url]\")\n",
    "        exit(1)\n",
    "    else:\n",
    "        logging.info(\"Downloading Kitti Road Data.\")\n",
    "        download(kitti_data_url, data_dir)\n",
    "\n",
    "# Extract and prepare KITTI DATA\n",
    "logging.info(\"Extracting kitti_road data.\")\n",
    "zipfile.ZipFile(data_road_zip, 'r').extractall(data_dir)\n",
    "kitti_road_dir = os.path.join(data_dir, 'data_road/')\n",
    "\n",
    "#logging.info(\"Preparing kitti_road data.\")\n",
    "\n",
    "train_txt = \"data/train3.txt\"\n",
    "val_txt = \"data/val3.txt\"\n",
    "testing_txt = \"data/testing.txt\"\n",
    "\n",
    "sys.stdout.flush()\n",
    "\n",
    "#copy2(train_txt, kitti_road_dir)\n",
    "#copy2(val_txt, kitti_road_dir)\n",
    "#copy2(testing_txt, kitti_road_dir)\n",
    "\n",
    "#logging.info(\"All data have been downloaded successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getData(txt):\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "\n",
    "    with open(txt, 'r') as f:\n",
    "        for line in f:\n",
    "            sys.stdout.write('\\r>> Processing %s          ' % (line.rstrip()))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            names = line.split()\n",
    "            #logging.info(names[0])\n",
    "            #logging.info(names[1])        \n",
    "            # load the image and apply SLIC and extract (approximately)\n",
    "\n",
    "            # the supplied number of segments\n",
    "            image = cv2.imread(os.path.join(kitti_road_dir, names[0]))\n",
    "            segments = slic(img_as_float(image), n_segments = 200, sigma = 5)\n",
    "\n",
    "            image2 = cv2.imread(os.path.join(kitti_road_dir, names[1]))\n",
    "            magenta = np.array([255, 0, 255], dtype=np.uint8)\n",
    "            #mask2 = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "            #mask2[image2 == magenta] = 255\n",
    "\n",
    "            #data = np.array(image2)\n",
    "            #rgb = data[:,:,:3]\n",
    "            #mask2 = np.all(rgb == magenta, axis = -1)\n",
    "\n",
    "            #lower_magenta = np.array([254,0,254])\n",
    "            #upper_magenta = np.array([255,1,255])\n",
    "            #mask2 = cv2.inRange(image2 , lower_magenta, upper_magenta)        \n",
    "\n",
    "            # ok\n",
    "            mask2 = np.all(image2 == magenta, axis = -1)\n",
    "            #plt.imshow(mask2)\n",
    "\n",
    "            # show the output of SLIC\n",
    "            #fig = plt.figure(\"Superpixels\")\n",
    "            #ax = fig.add_subplot(1, 1, 1)\n",
    "            #ax.imshow(mark_boundaries(img_as_float(cv2.cvtColor(image, cv2.COLOR_BGR2RGB)), segments))\n",
    "            #plt.axis(\"off\")\n",
    "            #plt.show()\n",
    "            # loop over the unique segment values\n",
    "            for (i, segVal) in enumerate(np.unique(segments)):\n",
    "                # construct a mask for the segment\n",
    "                #print(\"[x] inspecting segment %d\" % (i))\n",
    "\n",
    "                mask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "                mask[segments == segVal] = 255\n",
    "\n",
    "                m = cv2.moments(mask, True);\n",
    "                #print(\"centroid coordinates %d : %d\" % (m[\"m10\"]/m[\"m00\"], m[\"m01\"]/m[\"m00\"]))\n",
    "\n",
    "                x = m[\"m10\"]/m[\"m00\"]\n",
    "                y = m[\"m01\"]/m[\"m00\"]\n",
    "\n",
    "                intersection = np.logical_and(mask, mask2)\n",
    "\n",
    "\n",
    "                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                img = cv2.bitwise_and(gray, gray, mask = mask)\n",
    "\n",
    "                #intersection_mask = intersection.astype(np.uint8)\n",
    "                #intersection_mask *= 255\n",
    "                #img2 = cv2.bitwise_and(gray, gray, mask = intersection_mask)\n",
    "                #img2 = img2[int(y - img_rows/2) : int(y + img_rows/2), int(x - img_cols/2) : int(x + img_cols/2)]\n",
    "\n",
    "                #crop\n",
    "                img = img[int(y - img_rows/2) : int(y + img_rows/2), int(x - img_cols/2) : int(x + img_cols/2)]\n",
    "\n",
    "                old_size = img.shape[:2]\n",
    "                delta_w = img_cols - old_size[1]#img.cols\n",
    "                delta_h = img_rows - old_size[0]#img.rows\n",
    "                top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "                left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "                img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "\n",
    "                value = int(np.sum(intersection) > m[\"m00\"] / 2)\n",
    "                #print(\"value %d\" % (value))\n",
    "\n",
    "                #all_x.append(np.asarray(img[:,:]))\n",
    "                all_x.append([img])\n",
    "                all_y.append([value])\n",
    "\n",
    "                flipHorizontal = cv2.flip(img, 1)\n",
    "                all_x.append([flipHorizontal])\n",
    "                all_y.append([value])\n",
    "\n",
    "                #print(\"value %d\" % (value))\n",
    "\n",
    "                #if intersection.any():\n",
    "                #if m[\"m00\"] == np.sum(intersection):\n",
    "                #if np.sum(intersection) > m[\"m00\"] / 2:\n",
    "\n",
    "                # show the masked region\n",
    "                #v2.imshow(\"Mask\", mask)\n",
    "                #v2.imshow(\"Applied\", cv2.bitwise_and(image, image, mask = mask))\n",
    "\n",
    "                    #print(\"centroid, intersection counts %d %d\" % (m[\"m00\"], np.sum(intersection)))\n",
    "\n",
    "                    #m = cv2.moments(mask, True);\n",
    "                    #print(\"centroid coordinates %d : %d\" % (m[\"m10\"]/m[\"m00\"], m[\"m01\"]/m[\"m00\"]))\n",
    "\n",
    "                    #img = cv2.bitwise_and(image, image, mask = mask)\n",
    "                    #plt.imshow(img)\n",
    "                    #plt.imshow(img)\n",
    "                    #break\n",
    "            #break\n",
    "\n",
    "    all_x = np.concatenate(all_x)\n",
    "    all_y = np.concatenate(all_y)\n",
    "\n",
    "    #all_x = all_x.astype('float32')\n",
    "    #print('all_x shape:', all_x.shape)\n",
    "    #print(all_x)\n",
    "    #print('all_y shape:', all_y.shape)\n",
    "\n",
    "    return all_x, all_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Processing training/image_2/uu_000097.png training/gt_image_2/uu_road_000097.png            "
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train) = getData(train_txt)\n",
    "(x_test, y_test) = getData(val_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (87160, 48, 48, 1)\n",
      "y_train shape: (87160,)\n",
      "87160 train samples\n",
      "17336 test samples\n",
      "WARNING:tensorflow:From C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Usrer\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 87160 samples, validate on 17336 samples\n",
      "Epoch 1/12\n",
      "87160/87160 [==============================] - 45s 517us/step - loss: 0.3293 - accuracy: 0.8544 - val_loss: 0.3601 - val_accuracy: 0.8163\n",
      "Epoch 2/12\n",
      "87160/87160 [==============================] - 39s 448us/step - loss: 0.2469 - accuracy: 0.8895 - val_loss: 0.2429 - val_accuracy: 0.8837\n",
      "Epoch 3/12\n",
      "87160/87160 [==============================] - 39s 449us/step - loss: 0.2224 - accuracy: 0.8992 - val_loss: 0.2438 - val_accuracy: 0.8947\n",
      "Epoch 4/12\n",
      "87160/87160 [==============================] - 39s 450us/step - loss: 0.2041 - accuracy: 0.9093 - val_loss: 0.2187 - val_accuracy: 0.9017\n",
      "Epoch 5/12\n",
      "87160/87160 [==============================] - 39s 450us/step - loss: 0.1801 - accuracy: 0.9221 - val_loss: 0.1909 - val_accuracy: 0.9111\n",
      "Epoch 6/12\n",
      "87160/87160 [==============================] - 39s 450us/step - loss: 0.1670 - accuracy: 0.9297 - val_loss: 0.1948 - val_accuracy: 0.9202\n",
      "Epoch 7/12\n",
      "87160/87160 [==============================] - 39s 450us/step - loss: 0.1520 - accuracy: 0.9375 - val_loss: 0.1714 - val_accuracy: 0.9184\n",
      "Epoch 8/12\n",
      "87160/87160 [==============================] - 39s 450us/step - loss: 0.1388 - accuracy: 0.9426 - val_loss: 0.1999 - val_accuracy: 0.9229\n",
      "Epoch 9/12\n",
      "87160/87160 [==============================] - 39s 450us/step - loss: 0.1290 - accuracy: 0.9473 - val_loss: 0.1800 - val_accuracy: 0.9270\n",
      "Epoch 10/12\n",
      "87160/87160 [==============================] - 39s 450us/step - loss: 0.1211 - accuracy: 0.9512 - val_loss: 0.1895 - val_accuracy: 0.9278\n",
      "Epoch 11/12\n",
      "87160/87160 [==============================] - 39s 450us/step - loss: 0.1135 - accuracy: 0.9553 - val_loss: 0.1859 - val_accuracy: 0.9294\n",
      "Epoch 12/12\n",
      "87160/87160 [==============================] - 39s 450us/step - loss: 0.1053 - accuracy: 0.9587 - val_loss: 0.1877 - val_accuracy: 0.9210\n",
      "Test loss: 0.18771649368249574\n",
      "Test accuracy: 0.9209737181663513\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(52, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
